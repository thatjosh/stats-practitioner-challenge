{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S&P500 VIX Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import utils\n",
    "\n",
    "load_dotenv()\n",
    "file_path = os.getenv(\"FILE_PATH\")\n",
    "SNP_VIX_file = f'{file_path}/S&P 500 VIX.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vol</th>\n",
       "      <th>log_vol_diff</th>\n",
       "      <th>log_vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>19.92</td>\n",
       "      <td>-0.058496</td>\n",
       "      <td>2.991724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>21.12</td>\n",
       "      <td>0.089597</td>\n",
       "      <td>3.050220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>19.31</td>\n",
       "      <td>0.126822</td>\n",
       "      <td>2.960623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>17.01</td>\n",
       "      <td>-0.031253</td>\n",
       "      <td>2.833801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-09</th>\n",
       "      <td>17.55</td>\n",
       "      <td>-0.110476</td>\n",
       "      <td>2.865054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              vol  log_vol_diff   log_vol\n",
       "2015-01-05  19.92     -0.058496  2.991724\n",
       "2015-01-06  21.12      0.089597  3.050220\n",
       "2015-01-07  19.31      0.126822  2.960623\n",
       "2015-01-08  17.01     -0.031253  2.833801\n",
       "2015-01-09  17.55     -0.110476  2.865054"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file into df\n",
    "VIX = pd.read_csv(SNP_VIX_file)\n",
    "VIX.columns = [\"vol\"]\n",
    "VIX[\"log_vol_diff\"] = np.log(VIX['vol']/ VIX['vol'].shift(1))\n",
    "VIX.index = pd.to_datetime(VIX.index)\n",
    "VIX = VIX.sort_index(ascending=True)\n",
    "VIX = VIX[1:]\n",
    "VIX['log_vol'] = np.log(VIX['vol'])\n",
    "\n",
    "VIX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vol</th>\n",
       "      <th>log_vol_diff</th>\n",
       "      <th>log_vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>9.77</td>\n",
       "      <td>0.065563</td>\n",
       "      <td>2.279316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>9.15</td>\n",
       "      <td>-0.007621</td>\n",
       "      <td>2.213754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>9.22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.221375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>9.22</td>\n",
       "      <td>-0.032020</td>\n",
       "      <td>2.221375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>9.52</td>\n",
       "      <td>-0.057158</td>\n",
       "      <td>2.253395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             vol  log_vol_diff   log_vol\n",
       "2018-01-02  9.77      0.065563  2.279316\n",
       "2018-01-03  9.15     -0.007621  2.213754\n",
       "2018-01-04  9.22      0.000000  2.221375\n",
       "2018-01-05  9.22     -0.032020  2.221375\n",
       "2018-01-08  9.52     -0.057158  2.253395"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vix_training_start, vix_training_end = \"2015-01-02\", \"2022-12-30\"\n",
    "vix_training_start, vix_training_end = \"2018-01-01\", \"2020-06-30\"\n",
    "vix_testing_start, vix_testing_end = \"2020-07-01\", \"2020-08-01\"\n",
    "\n",
    "vix_training_df = VIX[(VIX.index >= vix_training_start) & (VIX.index <= vix_training_end)]\n",
    "vix_testing_df = VIX[(VIX.index >= vix_testing_start) & (VIX.index <= vix_testing_end)]\n",
    "vix_training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Hurst Exponent: 0.6277\n"
     ]
    }
   ],
   "source": [
    "from hurst import compute_Hc\n",
    "\n",
    "vix_hurst_est, c, data = compute_Hc(vix_training_df[\"log_vol\"], kind='change', simplified=True)\n",
    "print(f\"Estimated Hurst Exponent: {vix_hurst_est:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Hurst exponent (Aggregated Variance): 0.34803462555340936\n"
     ]
    }
   ],
   "source": [
    "# Aggregated variance method\n",
    "\n",
    "def hurst_aggregated_variance(series, min_window=10, max_window=None):\n",
    "    \"\"\"\n",
    "    Estimate the Hurst exponent using Aggregated Variance method.\n",
    "    \n",
    "    Parameters:\n",
    "    series : array-like\n",
    "        The time series data.\n",
    "    min_window : int\n",
    "        Minimum window size.\n",
    "    max_window : int or None\n",
    "        Maximum window size (default is len(series) // 2).\n",
    "    \n",
    "    Returns:\n",
    "    float\n",
    "        Estimated Hurst exponent.\n",
    "    \"\"\"\n",
    "    if max_window is None:\n",
    "        max_window = len(series) // 2\n",
    "\n",
    "    windows = np.logspace(np.log10(min_window), np.log10(max_window), num=20, dtype=int)\n",
    "    var_values = []\n",
    "\n",
    "    for w in windows:\n",
    "        segments = [series[i:i+w] for i in range(0, len(series) - w, w)]\n",
    "        segment_means = [np.mean(seg) for seg in segments]\n",
    "        var_values.append(np.var(segment_means))\n",
    "\n",
    "    log_var = np.log(var_values)\n",
    "    log_n = np.log(windows[:len(log_var)])\n",
    "\n",
    "    H, _ = np.polyfit(log_n, log_var, 1)  # Slope is 2H - 2\n",
    "    return (H + 2) / 2\n",
    "\n",
    "# Example Usage:\n",
    "hurst_estimate_var = hurst_aggregated_variance(vix_training_df['log_vol'])\n",
    "print(f\"Estimated Hurst exponent (Aggregated Variance): {hurst_estimate_var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hurst import compute_Hc\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def compute_rolling_hurst(df, window, col='log_vol_diff', lag=0):\n",
    "    hurst_values = []\n",
    "    times = []\n",
    "    \n",
    "    # Loop through the DataFrame using the rolling window\n",
    "    for i in range(window - 1, len(df), lag+1):\n",
    "        # Extract the window slice from the series\n",
    "        window_series = df[col].iloc[i - window + 1 : i + 1: lag+1]\n",
    "        # Compute the Hurst exponent using the 'change' method and simplified calculation\n",
    "        h, _, _ = compute_Hc(window_series, kind='change', simplified=True)\n",
    "        \n",
    "        hurst_values.append(h)\n",
    "        times.append(df.index[i])\n",
    "    \n",
    "    # Create and return a new DataFrame with the computed Hurst exponents\n",
    "    result_df = pd.DataFrame({'hurst': hurst_values}, index=times)\n",
    "    return result_df\n",
    "\n",
    "rolling_hurst_150 = compute_rolling_hurst(VIX, window=150, col='log_vol', lag=0)\n",
    "rolling_hurst_350 = compute_rolling_hurst(VIX, window=300, col='log_vol', lag=0)\n",
    "rolling_hurst_500 = compute_rolling_hurst(VIX, window=500, col='log_vol', lag=0)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=rolling_hurst_150.index,\n",
    "    y=rolling_hurst_150[\"hurst\"],\n",
    "    mode='lines',\n",
    "    name='150 days rolling window',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=rolling_hurst_350.index,\n",
    "    y=rolling_hurst_350[\"hurst\"],\n",
    "    mode='lines',\n",
    "    name='350 days rolling window',\n",
    "    line=dict(color='red')\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=rolling_hurst_500.index,\n",
    "    y=rolling_hurst_500[\"hurst\"],\n",
    "    mode='lines',\n",
    "    name='500 days rolling window',\n",
    "    line=dict(color='green')\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=f\"Hurst exponent for volatility\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Hurst Value\",\n",
    "    template=\"plotly_white\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup object\n",
    "vix_training_data_obj = utils.VixDf(vix_training_df)\n",
    "\n",
    "# Simulate 1 day\n",
    "next_day_pred = utils.simulate_fbm_ndays(vix_training_data_obj, 0.3, 1)\n",
    "print(f'Next day prediction: {next_day_pred}')\n",
    "\n",
    "# Attempts to predict 5 days\n",
    "utils.apply_rolling_function(vix_training_data_obj, 500, 5)\n",
    "print(f'Next 5 days prediction: {next_day_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vix_training_data_obj.get_df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run fBM Model on data post-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vix_obj = utils.VixDf(VIX)\n",
    "result_df = utils.apply_rolling_predictions_from_start(vix_obj, '2022-01-01', 150)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = result_df.join(VIX, how='inner')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.compute_rmse(merged_df, 'predicted', 'vol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=merged_df.index,\n",
    "    y=merged_df[\"predicted\"],\n",
    "    mode='lines',\n",
    "    name='Predicted',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=merged_df.index,\n",
    "    y=merged_df[\"vol\"],\n",
    "    mode='lines',\n",
    "    name='Actual',\n",
    "    line=dict(color='red')\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=f\"Predicted vs Actual Volatility\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Volatility\",\n",
    "    template=\"plotly_white\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from scipy import stats\n",
    "\n",
    "# Example DataFrame: df should already have a time series index and the columns 'observed' and 'predicted'\n",
    "# df = pd.read_csv('your_data.csv', index_col='date', parse_dates=True)\n",
    "\n",
    "# 1. Compute the residuals\n",
    "df = merged_df \n",
    "df['residual'] = df['vol'] - df['predicted']\n",
    "\n",
    "# 2. Plot the residuals over time\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(df.index, df['residual'], label='Residuals')\n",
    "plt.title(\"Residuals Over Time\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Occasional large spikes, indicating outliers \n",
    "- Residuals oscillate around zero (good)\n",
    "- No obvious trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Plot the Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF)\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 8))\n",
    "plot_acf(df['residual'], lags=20, ax=ax[0])\n",
    "plot_pacf(df['residual'], lags=20, ax=ax[1])\n",
    "ax[0].set_title(\"ACF of Residuals\")\n",
    "ax[1].set_title(\"PACF of Residuals\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- No signification autocorrelation (since no spikes), captured temporal dependencies well\n",
    "- Good fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Q-Q Plot for normality check of the residuals\n",
    "plt.figure(figsize=(6, 6))\n",
    "stats.probplot(df['residual'], dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q Plot of Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Observed heavy tails, indicating that there are outliers\n",
    "- Non-normal distribution, (probably t distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Histogram of the residuals\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(df['residual'], kde=True)\n",
    "plt.title(\"Histogram of Residuals\")\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- roughly centered around zero, slightly negative, a bit of overpredicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Perform a normality test (Shapiro-Wilk Test)\n",
    "stat, p_value = stats.shapiro(df['residual'])\n",
    "print(f'Shapiro-Wilk Test statistic: {stat:.4f}, p-value: {p_value:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "-  A very small p-value means we reject the null hypothesis that states that residuals are normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts from plots:\n",
    "- Standard fBM assumes increments follow a normal distribution, but clearly this isn't the case here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Volatility Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vix_obj = utils.VixDf(VIX)\n",
    "high_vol_df = utils.apply_rolling_predictions_from_start(vix_obj, '2020-01-01', 150)\n",
    "high_vol_df = high_vol_df[(high_vol_df.index >= '2020-01-01') & (high_vol_df.index <= '2022-01-01')]\n",
    "high_vol_df = high_vol_df.join(VIX, how='inner')\n",
    "utils.compute_rmse(high_vol_df, 'predicted', 'vol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Vol Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vix_obj = utils.VixDf(VIX)\n",
    "low_vol_df = utils.apply_rolling_predictions_from_start(vix_obj, '2018-01-01', 150)\n",
    "low_vol_df = low_vol_df[(low_vol_df.index >= '2018-01-01') & (low_vol_df.index <= '2020-01-01')]\n",
    "low_vol_df = low_vol_df.join(VIX, how='inner')\n",
    "utils.compute_rmse(low_vol_df, 'predicted', 'vol')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
